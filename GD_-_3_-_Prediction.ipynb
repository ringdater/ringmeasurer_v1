{"cells":[{"cell_type":"markdown","metadata":{"id":"ocr-MYJFsu93"},"source":["## Perform predictions using the trained model\n","\n","This notebook contains the code to carry out predictions with the trained\n","models. Note that it is currently set up only to carry out segmentations\n","(predictions) for the left out images in the case of the LOIO experiments, and\n","for the images defined in the `test_images` list in the configuration file for\n","the *final* model. We briefly summarise the prediction process. For a given\n","test image and its hand-drawn axis of maximum growth image, predictions are\n","generated as follows:\n","\n","1. The growth axis is extracted from the given growth axis image.\n","2. Patches the same size as those used to train the model are extracted along\n","    the growth axis, with a user-defined stride\n","    (we use 16 pixels in this work).\n","3. The model predicts the segmentation mask of each extracted patch.\n","4. Predictions are saved to the same folder the model is stored in.\n","\n","Please see the project [README](./README.md) for full details of the prediction\n","procedure."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7068,"status":"ok","timestamp":1644580123658,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"Ep-WmlAcR24P","outputId":"a109def4-4849-4f31-bfbb-49934efd8479"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imagecodecs\n","  Downloading imagecodecs-2021.11.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n","\u001b[K     |████████████████████████████████| 31.0 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from imagecodecs) (1.19.5)\n","Installing collected packages: imagecodecs\n","Successfully installed imagecodecs-2021.11.20\n"]}],"source":["# We need the imagecodecs package for imageio (used in a library) to\n","# parse .tif files -- this can be skipped if no .tif files are used.\n","%pip install imagecodecs"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1624,"status":"ok","timestamp":1644580125270,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"2bwvM2Alkgrk"},"outputs":[],"source":["import os\n","import google\n","import yaml\n","import tqdm.notebook\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":195,"status":"ok","timestamp":1644580125459,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"QkSQ5AO9khEr"},"outputs":[],"source":["# SETTINGS\n","google_drive_path = r\"/content/gdrive/MyDrive/2021-07_Rings_Project\"\n","\n","# auto-reload modules\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13901,"status":"ok","timestamp":1644580139354,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"FAadOGLOkiIh","outputId":"785d3472-c0c5-45fe-db6b-7d7f7f652044"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/2021-07_Rings_Project\n","Config file loaded\n"]}],"source":["# mount Google drive (local/home version)\n","google.colab.drive.mount(\"/content/gdrive\")\n","\n","# change to the base directory that contains the setting file and where\n","# we wish to save the trained models to\n","%cd {google_drive_path}\n","\n","# load the config file\n","with open(\"config.yaml\", \"r\") as fd:\n","    cfg = yaml.safe_load(fd)\n","print('Config file loaded')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2244,"status":"ok","timestamp":1644580142156,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"TfkD3IN6lrkh"},"outputs":[],"source":["# import our needed functions. Note that these are hosted on the google drive,\n","# so we have to connect to it first.\n","from shellai import preprocessing, tf_util"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31375,"status":"ok","timestamp":1644580173523,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"W2tiTD2lNzL0","outputId":"4f1a173e-12ad-4c13-c68f-cb6cbabceb3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["OS Version & Details: \n","No LSB modules are available.\n","Distributor ID:\tUbuntu\n","Description:\tUbuntu 18.04.5 LTS\n","Release:\t18.04\n","Codename:\tbionic\n","\n","TPU is allocated successfully at location: grpc://10.37.56.18:8470.\n","INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.37.56.18:8470\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.37.56.18:8470\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}],"source":["# connect to the TPU -- this greatly speeds up predictions\n","print(\"OS Version & Details: \")\n","!lsb_release -a\n","print()\n","\n","tpu_device_location = f\"grpc://{os.environ['COLAB_TPU_ADDR']}\"\n","print(f\"TPU is allocated successfully at location: {tpu_device_location}.\")\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_device_location)\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","strategy = tf.distribute.TPUStrategy()"]},{"cell_type":"markdown","metadata":{"id":"WZHulv-SWx9K"},"source":["### Leave-one-image-out predictions\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E8Dp3epSX7IB"},"outputs":[],"source":["# experimental settings\n","\n","# list of image names. For each image, we train a model on all other images and\n","# test on the left out image\n","test_images = cfg['images']['train_images']\n","\n","# size of patches to extract for prediction\n","# (this should be the same as the model was trained on)\n","patch_shape = tuple(cfg['testing']['patch_shape'])\n","\n","# stride (in pixels) between extracted patches\n","stride_step = cfg['testing']['stride']\n","\n","# batch size to push through the model (too large causes memory issues)\n","batch_size = cfg['testing']['batch_size']\n","\n","# directory containing directories of training images\n","base_dir = cfg['images']['train_dir']\n","\n","# directory containing directories of saved models. note that we will also save\n","# predictions to the corresponding model's directory\n","saved_model_dir = \"saved_models\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N57IZzadWwtS"},"outputs":[],"source":["# perform predictions for each model (i.e predict each test image)\n","for test_image in tqdm.notebook.tqdm(test_images, leave=False):\n","    # directory where the models are saved\n","    model_dir = f\"{saved_model_dir}/{test_image}\"\n","\n","    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n","    # PLOT THE OPTIMISATION HISTORY\n","    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n","    history_path = f\"{model_dir}/history.npz\"\n","\n","    with np.load(history_path, allow_pickle=True) as fd:\n","        history = fd['history'].item()\n","\n","    keys = [key for key in history if \"val\" not in key]\n","\n","    start = 0\n","    n = len(history[keys[0]])\n","\n","    fig, axes = plt.subplots(1, len(keys), figsize=(15, 5), sharex=True)\n","    axes = axes if len(keys) > 1 else [axes]\n","    for ax, key in zip(axes, keys):\n","        ax.plot(\n","            range(1 + start, n + 1),\n","            history[key][start:],\n","            label=\"Training\",\n","            alpha=0.5,\n","        )\n","        ax.plot(\n","            range(1 + start, n + 1),\n","            history[f\"val_{key:s}\"][start:],\n","            label=\"Validation\",\n","            alpha=0.5,\n","        )\n","        ax.legend(loc=\"best\")\n","        ax.set_title(key)\n","\n","        ax.semilogy()\n","        ax.set_xlabel(\"epochs\")\n","\n","        for xl in range(5, n+5, 5):\n","            ax.axvline(x=xl, ls='-', c='k', alpha=0.1)\n","\n","    plt.tight_layout()\n","\n","    savepath = os.path.join(model_dir, \"history.png\")\n","    # plt.savefig(savepath, bbox_inchest='tight')\n","    plt.close()\n","    print(f'History plot saved to: {savepath}')    \n","\n","    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n","    # PERFORM PREDICTIONS\n","    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n"," \n","    # load the image and image of the drawn line (not binary!)\n","    image, line_mask, _ = preprocessing.load_image_data(\n","        base_dir, test_image\n","    )\n","\n","    # get the coords of the test patches (patch_coords), their centres (lc), \n","    # and the coordinates of the hand-drawn axis of maximum growth (full_lc)\n","    patch_coords, lc, full_lc = tf_util.get_test_patch_locations(\n","        line_mask, patch_shape, stride_step\n","    )\n","\n","    # create the test dataset\n","    with strategy.scope():\n","        test_ds = tf_util.convert_patches_into_tf_ds(\n","            patch_coords, image, batch_size=batch_size\n","        )\n","    \n","    # get the patch to each saved model (we save one ever N iterations)\n","    model_paths = tf.io.gfile.glob(\n","        os.path.join(model_dir, 'model_checkpoint_*.h5')\n","    )\n","\n","    # for each model, perform the predictions\n","    for model_path in tqdm.notebook.tqdm(model_paths, leave=False):\n","        model_name = os.path.basename(model_path.split('.')[0])\n","        save_path = os.path.join(model_dir, f\"{model_name:s}_predictions.npz\")\n","\n","        # if the predictions already exist, skip them\n","        if os.path.exists(save_path):\n","            print(f'Skipping: {save_path}')\n","            continue\n","\n","        # otherwise, load the model on the TPU\n","        with strategy.scope():\n","            model = tf.keras.models.load_model(model_path)\n","\n","        # predict all the images of the test dataset (batched)\n","        predictions = []\n","\n","        for batch in test_ds:\n","            # make the prediction\n","            pred = model(batch, training=False)\n","\n","            # convert to numpy and store\n","            predictions.append(pred.numpy().squeeze())\n","\n","        # join together the predictions\n","        predictions = np.concatenate(predictions, axis=0)\n","        \n","        # finally, save them\n","        np.savez(\n","            save_path,\n","            predictions=predictions,\n","            full_line_coords=full_lc,\n","            patch_centres=lc,\n","            patch_coords=patch_coords\n","        )\n","\n","        print('Saved:', save_path)"]},{"cell_type":"markdown","metadata":{"id":"FZ8CM90y2RFT"},"source":["### Final model predictions"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1644580206970,"user":{"displayName":"George De Ath","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08187554398241365274"},"user_tz":0},"id":"oUq3OAeN2fnI"},"outputs":[],"source":["# experimental settings\n","\n","# test images -- these have not been seen by the final model before\n","unseen_test_images = cfg['images']['test_images']\n","\n","# size of patches to extract for prediction\n","# (this should be the same as the model was trained on)\n","patch_shape = tuple(cfg['testing']['patch_shape'])\n","\n","# stride (in pixels) between extracted patches\n","stride_step = cfg['testing']['stride']\n","\n","# batch size to push through the model (too large causes memory issues)\n","batch_size = cfg['testing']['batch_size']\n","\n","# directory containing directories of images\n","base_dir = cfg['images']['test_dir']\n","\n","# directory containing directories of saved models. note that we will also save\n","# predictions to the corresponding model's directory\n","saved_model_dir = \"saved_models\"\n","\n","# final model name (this is the directory name stored in the dir above)\n","final_model_name = \"final_model\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NM8i9xtuXGdw"},"outputs":[],"source":["# Note: - we only have one model because we trained on all training images.\n","#       - no history is avaliable because we have no validation data\n","model_dir = f\"{saved_model_dir}/{final_model_name}\"\n","model_paths = tf.io.gfile.glob(os.path.join(model_dir, 'model_checkpoint_*.h5'))\n","\n","for image_name in tqdm.notebook.tqdm(unseen_test_images):\n","    # load the image and image of the drawn line (not binary!)\n","    image, line_mask = preprocessing.load_image_data(\n","        base_dir, image_name, no_rings=True\n","    )\n","\n","    # get the coords of the test patches (patch_coords), their centres (lc), \n","    # and the coordinates of the hand-drawn axis of maximum growth (full_lc)\n","    patch_coords, lc, full_lc = tf_util.get_test_patch_locations(\n","        line_mask, patch_shape, stride_step\n","    )\n","\n","    # create the test dataset\n","    with strategy.scope():\n","        test_ds = tf_util.convert_patches_into_tf_ds(\n","            patch_coords, image, batch_size=batch_size\n","        )\n","\n","    # for each model, perform the predictions\n","    for model_path in tqdm.notebook.tqdm(model_paths, leave=False):\n","        model_name = os.path.basename(model_path.split('.')[0])\n","        save_path = os.path.join(model_dir, f\"{model_name:s}_predictions_{image_name:s}.npz\")\n","\n","        # if the predictions already exist, skip them\n","        if os.path.exists(save_path):\n","            print(f'Skipping: {save_path}')\n","            continue\n","\n","        # otherwise, load the model on the TPU\n","        with strategy.scope():\n","            model = tf.keras.models.load_model(model_path)\n","\n","        # predict all the images of the test dataset (batched)\n","        predictions = []\n","\n","        for batch in test_ds:\n","            # make the prediction\n","            pred = model(batch, training=False)\n","\n","            # convert to numpy and store\n","            predictions.append(pred.numpy().squeeze())\n","\n","        # join together the predictions\n","        predictions = np.concatenate(predictions, axis=0)\n","\n","        # finally, save them\n","        np.savez(\n","            save_path,\n","            predictions=predictions,\n","            full_line_coords=full_lc,\n","            patch_centres=lc,\n","            patch_coords=patch_coords\n","        )\n","\n","        print('Saved:', save_path)"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyP1LyKVqPAoIKU3Fj1Z1JYI","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"GD - 3 - Prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
