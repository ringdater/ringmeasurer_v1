{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a94e53",
   "metadata": {},
   "source": [
    "## Plot selected segmentation results\n",
    "\n",
    "This notebook facilitates the plotting of the segmented rings. Please see the\n",
    "project [README](./README.md) for further details of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0972f1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm.notebook\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shellai import preprocessing, tf_util\n",
    "\n",
    "# load the config file\n",
    "with open(\"config.yaml\", \"r\") as fd:\n",
    "    cfg = yaml.safe_load(fd)\n",
    "print('Config file loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcd97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #  General settings\n",
    "# directory containing the saved models and their corresponding raw predictions\n",
    "dir_saved_model = cfg['paths']['local']['model']\n",
    "\n",
    "# base directory to save things to\n",
    "dir_base = cfg['paths']['local']['base']\n",
    "\n",
    "# where we wish to save the plots to. this directory must exist\n",
    "dir_saved_plots = os.path.join(dir_base, \"output\", \"segmentation_plots\")\n",
    "\n",
    "# patch size\n",
    "patch_shape = tuple(cfg['training']['patch_shape'])\n",
    "\n",
    "# select which model configurations (i.e. which epoch(s) we wish to plot for\n",
    "plotting_epochs = [100, 150, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad52ff7",
   "metadata": {},
   "source": [
    "### Segmentation plots for the leave-one-image-out experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224d80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for the LOIO experiments\n",
    "\n",
    "# location of the training images\n",
    "base_image_dir = os.path.join(dir_base, cfg['images']['train_dir'])\n",
    "\n",
    "# list of the images used in training. each one corresponds to a model where\n",
    "# the model was trained on all but the named image.\n",
    "image_names = cfg['images']['train_images']\n",
    "\n",
    "# mask of the model predictions\n",
    "pred_file_mask = 'model_checkpoint_{epoch}_predictions.npz'\n",
    "\n",
    "# what we want the saved images to be called\n",
    "saved_image_name = \"loo_{image_name}_{epoch}.png\"\n",
    "saved_dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bec21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in tqdm.notebook.tqdm(image_names):\n",
    "    # load the image and ground-truth segmentation\n",
    "    image, _, ring_mask_full = preprocessing.load_image_data(\n",
    "        base_image_dir, image_name\n",
    "    )\n",
    "    ring_mask = preprocessing.threshold_drawn_mask_and_skeletonize(\n",
    "        ring_mask_full, sparse=False\n",
    "    )\n",
    "    \n",
    "    gt_mask = original_slice_image = None\n",
    "\n",
    "    for epoch in plotting_epochs:\n",
    "        savepath = os.path.join(\n",
    "            dir_saved_plots,\n",
    "            saved_image_name.format(image_name=image_name, epoch=epoch)\n",
    "        )\n",
    "\n",
    "        if os.path.exists(savepath):\n",
    "            print(f'Image already saved: {savepath}')\n",
    "            continue\n",
    "\n",
    "        pred_path = os.path.join(\n",
    "            dir_saved_model, image_name, pred_file_mask.format(epoch=epoch)\n",
    "        )\n",
    "\n",
    "        # load the predictions, and coordinates of each extracted patch, and\n",
    "        # their centres\n",
    "        with np.load(pred_path, allow_pickle=True) as fd:\n",
    "            predictions = fd['predictions']\n",
    "            # flc = fd['full_line_coords']\n",
    "            patch_coords = fd['patch_coords'] # [c0, c1, r0, r1]\n",
    "            patch_centres = fd['patch_centres'] # [idx0, idx1]\n",
    "\n",
    "        # only create the ground truth mask once per image\n",
    "        if gt_mask is None:\n",
    "            gt_mask = tf_util.place_patches_in_row_image(\n",
    "                ring_mask, patch_centres, patch_coords, patch_shape\n",
    "            )\n",
    "\n",
    "        # likewise for the image itself\n",
    "        if original_slice_image is None:\n",
    "            original_slice_image = tf_util.place_patches_in_row_image(\n",
    "                image, patch_centres, patch_coords, patch_shape\n",
    "            )\n",
    "\n",
    "        # create the prediction image\n",
    "        predicted_mask, _ = tf_util.create_patch_image(\n",
    "            patches=predictions,\n",
    "            patch_coords=patch_coords,\n",
    "            image_shape=image.shape\n",
    "        )\n",
    "\n",
    "        # create the image long just the extracted patches\n",
    "        pred_mask = tf_util.place_patches_in_row_image(\n",
    "            predicted_mask, patch_centres, patch_coords, patch_shape\n",
    "        )\n",
    "\n",
    "        # plot the images\n",
    "        fig, axes = plt.subplots(\n",
    "            3, 1, figsize=(15, 2), sharex=True, sharey=True, dpi=saved_dpi\n",
    "        )\n",
    "        axes[0].imshow(original_slice_image, aspect='auto')\n",
    "        axes[1].imshow(gt_mask, aspect='auto')\n",
    "        axes[2].imshow(pred_mask, aspect='auto')\n",
    "\n",
    "        axes[0].set_title(\n",
    "            f\"Experiment: Leave-one-image-out - Image: {image_name} - Epochs: {epoch}\"\n",
    "        )\n",
    "\n",
    "        for i in range(3):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.savefig(savepath)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f'Saved: {savepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e26127",
   "metadata": {},
   "source": [
    "### Segmentation plots for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12048218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for the final model experiment\n",
    "\n",
    "# location of the real images\n",
    "base_image_dir = os.path.join(dir_base, cfg['images']['test_dir'])\n",
    "\n",
    "# list of the images used in training. each one corresponds to a model where\n",
    "# the model was trained on all but the named image.\n",
    "image_names = cfg['images']['test_images']\n",
    "\n",
    "# mask of the model predictions\n",
    "pred_file_mask = 'model_checkpoint_{epoch}_predictions_{image_name:s}.npz'\n",
    "\n",
    "# what we want the saved images to be called\n",
    "saved_image_name = \"final_{image_name}_{epoch}.png\"\n",
    "saved_dpi = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59812bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in tqdm.notebook.tqdm(image_names):\n",
    "    # load the image and ground-truth segmentation\n",
    "    image, _, = preprocessing.load_image_data(\n",
    "        base_image_dir, image_name, no_rings=True\n",
    "    )\n",
    "\n",
    "    original_slice_image = None\n",
    "\n",
    "    for epoch in plotting_epochs:\n",
    "        savepath = os.path.join(\n",
    "            dir_saved_plots,\n",
    "            saved_image_name.format(image_name=image_name, epoch=epoch)\n",
    "        )\n",
    "\n",
    "        if os.path.exists(savepath):\n",
    "            print(f'Image already saved: {savepath}')\n",
    "            continue\n",
    "\n",
    "        pred_path = os.path.join(\n",
    "            dir_saved_model, \n",
    "            \"final_model\", \n",
    "            pred_file_mask.format(image_name=image_name, epoch=epoch)\n",
    "        )\n",
    "\n",
    "        # load the predictions, and coordinates of each extracted patch, and\n",
    "        # their centres\n",
    "        with np.load(pred_path, allow_pickle=True) as fd:\n",
    "            predictions = fd['predictions']\n",
    "            # flc = fd['full_line_coords']\n",
    "            patch_coords = fd['patch_coords'] # [c0, c1, r0, r1]\n",
    "            patch_centres = fd['patch_centres'] # [idx0, idx1]\n",
    "\n",
    "        # only create the slice image once per set of epochs\n",
    "        if original_slice_image is None:\n",
    "            original_slice_image = tf_util.place_patches_in_row_image(\n",
    "                image, patch_centres, patch_coords, patch_shape\n",
    "            )\n",
    "\n",
    "        # create the prediction image\n",
    "        predicted_mask, _ = tf_util.create_patch_image(\n",
    "            patches=predictions,\n",
    "            patch_coords=patch_coords,\n",
    "            image_shape=image.shape\n",
    "        )\n",
    "\n",
    "        # create the image long just the extracted patches\n",
    "        pred_mask = tf_util.place_patches_in_row_image(\n",
    "            predicted_mask, patch_centres, patch_coords, patch_shape\n",
    "        )\n",
    "\n",
    "        # plot the images\n",
    "        fig, axes = plt.subplots(\n",
    "            2, 1, figsize=(15, 1.75), sharex=True, sharey=True, dpi=saved_dpi\n",
    "        )\n",
    "        axes[0].imshow(original_slice_image, aspect='auto')\n",
    "        axes[1].imshow(pred_mask, aspect='auto')\n",
    "\n",
    "        axes[0].set_title(\n",
    "            f\"Experiment: Final model - Image: {image_name} - Epochs: {epoch}\"\n",
    "        )\n",
    "\n",
    "        for i in range(2):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.savefig(savepath)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f'Saved: {savepath}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
